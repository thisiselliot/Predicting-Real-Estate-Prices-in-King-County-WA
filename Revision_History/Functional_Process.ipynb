{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn packages\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFECV\n",
    "\n",
    "# Statsmodels\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pickle\n",
    "\n",
    "# utility libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Don't poly dummies (1**2 = 1)\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_polynomial(df_): # last step before modelling\n",
    "    poly_ = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    poly_data = poly_.fit_transform(df_)\n",
    "    poly_columns = poly_.get_feature_names(df_.columns)\n",
    "    \n",
    "    return pd.DataFrame(poly_data, columns=poly_columns)\n",
    "\"\"\"Don't poly dummies (1**2 = 1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lin_reg_model(df, target, random_state=34, test_size=0.2):\n",
    "    \n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(\n",
    "        df, target, random_state=34, test_size=0.2) # <---train test split\n",
    "    \n",
    "    lm = linear_model.LinearRegression().fit(\n",
    "        X_train_, y_train_) # <---linear regression model\n",
    "    \n",
    "    train_rmse = np.sqrt(metrics.mean_squared_error(\n",
    "        y_train_, lm.predict(X_train_))) # <---training RMSE\n",
    "    \n",
    "    test_rmse = np.sqrt(metrics.mean_squared_error(\n",
    "        y_test_, lm.predict(X_test_))) # <---test RMSE\n",
    "    \n",
    "#     print(list(zip(df.columns, lm.coef_))) #<---check coeffiecients\n",
    "    \n",
    "    return X_train_, X_test_, y_train_, y_test_, lm, train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlations(X_train_, X_test_):\n",
    "    corr_matrix = X_train_.corr().abs() # <---create correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # <---select upper triangle of correlation matrix\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.90)] # <---find index of feature columns with correlation greater than 0.90\n",
    "\n",
    "    X_train_ = X_train_.drop(columns=to_drop, inplace=False)\n",
    "    X_test_ = X_test_.drop(columns=to_drop, inplace=False)\n",
    "    \n",
    "    return X_train_, X_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vif(X_train_): #run before poly to get rid of high correlation features\n",
    "    vif_ = pd.DataFrame()\n",
    "    vif_[\"VIF Factor\"] = [variance_inflation_factor(X_train_.values, i) for i in range(X_train_.shape[1])]\n",
    "    vif_[\"features\"] = X_train_.columns\n",
    "    return vif_.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"how does each individual feature perform relative to the target\n",
    "\n",
    "looks at how each feature performs relative to the others\n",
    "\n",
    "run k-best a second time using entire data set to get coefficients for final model\n",
    "\n",
    "\n",
    "run k_best to reduce correlated catagories before lasso\"\"\"\n",
    "\n",
    "def get_k_best(X_train_, X_test_, y_train_, y_test_):\n",
    "    selector = SelectKBest(f_regression, k=50) # <--- F-Test (filter method; before fitting model)\n",
    "    selector.fit(X_train_, y_train_)\n",
    "    selected_columns = X_train_.columns[selector.get_support()]\n",
    "#     removed_columns = X_train_.columns[~selector.get_support()]\n",
    "\n",
    "    X_train_ = X_train_[selected_columns]\n",
    "    X_test_ = X_test_[selected_columns]\n",
    "    \n",
    "    lm = linear_model.LinearRegression().fit(\n",
    "        X_train_[selected_columns], y_train_) # <---linear regression model\n",
    "\n",
    "    train_rmse = np.sqrt(metrics.mean_squared_error(\n",
    "        y_train_, lm.predict(X_train_[selected_columns]))) # <---training RMSE\n",
    "\n",
    "    test_rmse = np.sqrt(metrics.mean_squared_error(\n",
    "        y_test_, lm.predict(X_test_[selected_columns]))) # <---test RMSE\n",
    "\n",
    "    return X_train_, X_test_, lm, train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_values():\n",
    "    \"\"\"run model then check p-values and remove highest as a manual wrapper method \n",
    "    or to explain rfe (auto wrapper method)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cross validation breaks training set into smaller train/tests and takes the average to\n",
    "hedge against variance\n",
    "\n",
    "wrapper method can check if accounting for interactions/variation in other features makes\n",
    "a feature more important than just an f-test would show, puts in context of whole model\n",
    "\n",
    "verbose for feedback\"\"\"\n",
    "\n",
    "def get_rfe(X_train_, X_test_, y_train_, y_test_):\n",
    "    ols = linear_model.LinearRegression() # <---create recursive feature eliminator\n",
    "    selector = RFECV(estimator=ols,\n",
    "                     step=1,\n",
    "                     cv=5,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     n_jobs=-1) # <---score features by mean squared errors (increase step size to make faster)\n",
    "    selector.fit(X_train_, y_train_) #<---fit recursive feature eliminator     \n",
    "    selected_columns = X_train_.columns[selector.support_]\n",
    "#     removed_columns = X_train_.columns[~selector.support_]\n",
    "    \n",
    "    X_train_ = X_train_[selected_columns]\n",
    "    X_test_ = X_test_[selected_columns]\n",
    "    \n",
    "    lm = linear_model.LinearRegression().fit(\n",
    "        X_train_[selected_columns], y_train_) # <---linear regression model\n",
    "\n",
    "    train_rfe_rmse = np.sqrt(metrics.mean_squared_error(\n",
    "        y_train_, lm.predict(X_train_[selected_columns]))) # <---training RMSE\n",
    "\n",
    "    test_rfe_rmse = np.sqrt(metrics.mean_squared_error(\n",
    "        y_test_, lm.predict(X_test_[selected_columns]))) # <---test RMSE\n",
    "\n",
    "    return X_train_, X_test_, lm, train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"can you tell from the test rmse and train rmse that your model is not overfitting?\n",
    "(test rmse is good relative to train rmse)\n",
    "\n",
    "\n",
    "investigate what the selected columns are before passing to holdout\"\"\"\n",
    "\n",
    "def finalize(df, target):\n",
    "    \"\"\"run kbest on ENTiRE dataset\"\"\"\n",
    "    selector = SelectKBest(f_regression, k=20)\n",
    "    selector.fit(df, target)\n",
    "\n",
    "    selected_columns = df.columns[selector.get_support()]\n",
    "    removed_columns = df.columns[~selector.get_support()]\n",
    "\n",
    "    lm = linear_model.LinearRegression().fit(df[selected_columns], target) # <---fit the linear regression to the data\n",
    "    lm.coef_ # <---final model for entire dataset\n",
    "\n",
    "    pickle_out = open(\"model.pickle\",\"wb\")\n",
    "    pickle.dump(lm, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    pickle_out = open(\"selected_columns.pickle\",\"wb\")\n",
    "    pickle.dump(selected_columns, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    # pickle_out = open(\"scaler.pickle\", \"wb\")\n",
    "    # pickle.dump(scaler, pickle_out)\n",
    "    # pickle_out.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw data\n",
    "df = pd.read_csv('clean_data_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='price', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, lm, train_rmse, test_rmse = run_lin_reg_model(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163795.2336650525"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170398.1073419808"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly = make_polynomial(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly, lm_poly, train_rmse_poly, test_rmse_poly = run_lin_reg_model(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163795.2336650525, 170398.1073419808)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse_poly, test_rmse_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = remove_correlations(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = get_vif(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kb, X_test_kb, lm_kb, train_rmse_kb, test_rmse_kb = get_k_best(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_kb, test_rmse_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe, X_test_rfe, lm_rfe, train_rmse_rfe, test_rmse_rfe = get_rfe(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163795.2336650525, 170398.1073419808)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse_rfe, test_rmse_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalize(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163795.2336650525, 170398.1073419808)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse_rfe, test_rmse_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
